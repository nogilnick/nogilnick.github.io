<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>nicholastsmith</title>
    <meta name="author" content="">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="../style.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>

<body>
    <div class="HeadImg">
        <div class="Header">
            <div style="display: table; height: 100%; width: 100%;">
                <div style="display: table-row; height: 100%; width: 100%;">
                    <div style="display: table-cell; height: 100%; padding: 0 0 0 0.5%; text-align: left; vertical-align: bottom; width: 64%;">
                        <a href="../index.html" style="text-decoration: none;"><text class="FontHeader"><b>nicholastsmith</b>.</text></a>
                    </div>
                    <div style="display: table-cell; height: 100%; padding: 0 0.5% 0 0; text-align: center; vertical-align: bottom; width: 12%;">
                        <a class="FontNavi" href="About.html">About</a>
                    </div>
                    <div style="display: table-cell; height: 100%; padding: 0 0.5% 0 0; text-align: center; vertical-align: bottom; width: 12%;">
                        <a class="FontNavi" href="../index.html">Blog</a>
                    </div>
                    <div style="display: table-cell; height: 100%; padding: 0 0.5% 0 0; text-align: center; vertical-align: bottom; width: 12%;">
                        <a class="FontNavi" href="Plots.html">Plots</a>
                    </div>
                </div>
            </div>
        </div>
        <br/><br/><br/>
        <text class="FontLogo"><b>The Website and Blog</b></text><br/>
        <text class="FontLogo">of</text><br/>
        <text class="FontLogo"><b>Nicholas T. Smith</b></text><br/>
        <text class="FontLogo"><i>The machine learns and I from the machine.</i></text>
        <br/><br/><br/><br/><br/><br/><br/><br/>
    </div>
    <div id="Cont" class="Contents">
        <div class="CTable">
            <div style="display: table-row; height: 100%; width: 100%;">
                <div class="BarLeft" id="LBar"></div>
                <div class="BarCenter" id="CBar"><br/><h1>Deep Learning OCR using TensorFlow and Python</h1><h2>Sat, 14 Oct 2017</h2><h3><i>Computer Science</i>, <i>Data Science</i>, <i>Deep Learning</i>, <i>Machine Learning</i>, <i>Ocr</i>, <i>Python</i>, <i>Tensorflow</i></h3>In this post, deep learning neural networks are applied to the problem of optical character recognition (OCR) using Python and TensorFlow. This post makes use of TensorFlow and the convolutional neural network class available in <a href="https://github.com/nicholastoddsmith/pythonml/blob/master/TFANN/TFANN.py">the TFANN module</a>. The full source code from this post is <a href="https://github.com/nicholastoddsmith/pythonml/tree/master/DeepOCR">available here</a>.
<h1>Introduction to OCR</h1>
OCR is the transformation of images of text into machine encoded text. A simple API to an OCR library might provide a function which takes as input an image and outputs a string. The following pseudo-code illustrates how this might be used.
<br/>
<br/>
<hr/><br/><pre style="margin: auto; border: 1px solid #B0B0B0B0; padding: 0.75%;max-width: 42vw; overflow-x: auto;"><code>#...
img = GetImage()
text = ImageToString(img)
ProcessText(text)
#...</code></pre><br/><hr/><br/>
<br/>
<br/>Figure 1 illustrates the OCR transformation.<br/>
<p style="text-align:center;">
<img src="../Img/ocrdiag.png" alt="OCRDiag" height="auto" width="75%" />
</p>
<p style="text-align:center;"><b>Figure 1: The OCR Process</b></p>
<br/>
The left and right sides depict an image of text and a string representation of the text respectively.
<h1>Deep Learning Based OCR</h1>
Traditional OCR techniques are typically multi-stage processes. For example, first the image may be divided into smaller regions that contain the individual characters, second the individual characters are recognized, and finally the result is pieced back together. A difficulty with this approach is to obtain a good division of the original image. This blog post explores using deep learning to provide a simplified OCR system.
<br/>
<br/>A fully convolutional network is presented which transforms the input volume into a sequence of character predictions. These character predictions can then be transformed into a string. The architecture of the network is shown below in Figure 2.<br/>
<p style="text-align:center;">
<img src="../Img/ocrarch.png" height="auto" width="75%" />
</p>
<p style="text-align:center;"><b>Figure 2: Deep OCR Architecture</b></p>
<br/>
Where \(N\) is the number of possible characters. In this example, there are 63 possible characters for uppercase and lowercase characters, digits, and a blank character. The parenthesized values in the convolutional layers are the filter sizes and stride values from top to bottom respectively. The values in the reshape layer are the reshaped dimension.
<br/>
<br/>The input volume is a rectangular RGB image. This first height and width of this volume are reduced across the convolutional layers using striding. The 3rd dimension of this volume increases from 3 channels (RGB) to 1 channel for each character possible. Thus, the volume is transformed from an RGB image into a sequence of vectors. Applying <i>argmax</i> across the channel dimension gives a sequence of 1-hot encoded vectors which can be transformed into a string.
<h1>Generating Data</h1>
To facilitate training this network, a dataset is generated using the Python Imaging Library (PIL). Random strings consisting of alphanumeric characters are generated.  Using PIL, images are generated for each random string. A CSV file is also generated which contains the file name and the associated random string. Some examples from the generated dataset are shown below in Figure 3.<br/>
<p style="text-align:center;">
<img src="../Img/4.png" alt="4" height="auto" width="75%" />
<p style="text-align:center;"><img src="../Img/3.png" alt="3" height="auto" width="75%" /></p>
<p style="text-align:center;"><img src="../Img/2.png" alt="2" height="auto" width="75%" /></p>
<p style="text-align:center;"><img src="../Img/1.png" alt="1" height="auto" width="75%" /></p>
<p style="text-align:center;"><img src="../Img/0.png" alt="0" height="auto" width="75%" /></p>
</p>
<p style="text-align:center;"><b>Figure 3: Generated Dataset Images</b></p>
<br/>
Code to generate the dataset follows.
<br/>
<br/>
<hr/><br/><pre style="margin: auto; border: 1px solid #B0B0B0B0; padding: 0.75%;max-width: 42vw; overflow-x: auto;"><code>import numpy as np
import string
from PIL import Image, ImageFont, ImageDraw

def MakeImg(t, f, fn, s = (100, 100), o = (16, 8)):
    '''
    Generate an image of text
    t:      The text to display in the image
    f:      The font to use
    fn:     The file name
    s:      The image size
    o:      The offest of the text in the image
    '''
    img = Image.new('RGB', s, "black")
    draw = ImageDraw.Draw(img)
    draw.text(OFS, t, (255, 255, 255), font = f)
    img.save(fn)

#The possible characters to use
CS = list(string.ascii_letters) + list(string.digits)
RTS = list(np.random.randint(10, 64, size = 8192)) + [64]
#The random strings
S = [''.join(np.random.choice(CS, i)) for i in RTS]
#Get the font
font = ImageFont.truetype("LiberationMono-Regular.ttf", 16)
#The largest size needed
MS = max(font.getsize(Si) for Si in S)
#Computed offset
OFS = ((640 - MS[0]) // 2, (32 - MS[1]) // 2)
#Image size
MS = (640, 32)
Y = []
for i, Si in enumerate(S):
    MakeImg(Si, font, str(i) + '.png', MS, OFS)
    Y.append(str(i) + '.png,' + Si)
#Write CSV file
with open('Train.csv', 'w') as F:
    F.write('\n'.join(Y))</code></pre><br/><hr/><br/>
<h1>Training the Network</h1>
To train the network, the CSV file is parsed and the images are loaded into memory. Each target value for the training data is a sequence of 1-hot vectors. Thus the target matrix is a 3D matrix with the three dimensions corresponding to sample, character, and 1-hot encoding respectively.
<br/>
<br/>
<hr/><br/><pre style="margin: auto; border: 1px solid #B0B0B0B0; padding: 0.75%;max-width: 42vw; overflow-x: auto;"><code>import numpy as np
import os
import string
import sys
from skimage.io import imread
from sklearn.model_selection import ShuffleSplit
from TFANN import ANNC

def LoadData(FP = '.'):
    '''
    Loads the OCR dataset. A is matrix of images (NIMG, Height, Width, Channel).
    Y is matrix of characters (NIMG, MAX_CHAR)
    FP:     Path to OCR data folder
    return: Data Matrix, Target Matrix, Target Strings
    '''
    TFP = os.path.join(FP, 'Train.csv')
    A, Y, T, FN = [], [], [], []
    with open(TFP) as F:
        for Li in F:
            FNi, Yi = Li.strip().split(',')                     #filename,string
            T.append(Yi)
            A.append(imread(os.path.join(FP, 'Out', FNi)))
            Y.append(list(Yi) + [' '] * (MAX_CHAR - len(Yi)))   #Pad strings with spaces
            FN.append(FNi)
    return np.stack(A), np.stack(Y), np.stack(T), np.stack(FN)</code></pre><br/><hr/><br/>
<br/>
<br/>Next the neural network is constructed using the artificial neural network classifier (ANNC) class from <a href="https://github.com/nicholastoddsmith/pythonml/blob/master/TFANN/TFANN.py">TFANN</a>. The architecture described above is represented in the following lines of code using ANNC.
<br/>
<br/>
<hr/><br/><pre style="margin: auto; border: 1px solid #B0B0B0B0; padding: 0.75%;max-width: 42vw; overflow-x: auto;"><code>#Architecture of the neural network
NC = len(string.ascii_letters + string.digits + ' ')
MAX_CHAR = 64
IS = (14, 640, 3)       #Image size for CNN
ws = [('C', [4, 4,  3, NC // 2], [1, 2, 2, 1]), ('AF', 'relu'), 
      ('C', [4, 4, NC // 2, NC], [1, 2, 1, 1]), ('AF', 'relu'), 
      ('C', [8, 5, NC, NC], [1, 8, 5, 1]), ('AF', 'relu'),
      ('R', [-1, 64, NC])]
#Create the neural network in TensorFlow
cnnc = ANNC(IS, ws, batchSize = 64, learnRate = 5e-5, maxIter = 32, reg = 1e-5, tol = 1e-2, verbose = True)
if not cnnc.RestoreModel('TFModel/', 'ocrnet'):
#...</code></pre><br/><hr/><br/>
<br/>
<br/>Softmax cross-entropy is used as the loss function which is performed over the 3rd dimension of the output.
<br/>
<br/>Fitting the network and performing predictions is simple using the ANNC class. The prediction is split up using <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.array_split.html">array_split from numpy</a> to prevent out of memory errors.
<br/>
<br/>
<hr/><br/><pre style="margin: auto; border: 1px solid #B0B0B0B0; padding: 0.75%;max-width: 42vw; overflow-x: auto;"><code>#Fit the network
cnnc.fit(A, Y)
#The predictions as sequences of character indices
YH = np.zeros((Y.shape[0], Y.shape[1]), dtype = np.int)
for i in np.array_split(np.arange(A.shape[0]), 32): 
    YH[i] = np.argmax(cnnc.predict(A[i]), axis = 2)
#Convert from sequence of char indices to strings
PS = [''.join(CS[j] for j in YHi) for YHi in YH]
for PSi, Ti in zip(PS, T):
    print(Ti + '\t-&gt;\t' + PSi)</code></pre><br/><hr/><br/>
<h1>Results</h1>
Training and cross-validation results are shown below in Figure 4 on the left and right respectively. The graphs are shown separately as the plots nearly coincide.<br/>
<p style="text-align:center;">
<img src="../Img/netperf.png" height="auto" width="75%" />
</p>
<p style="text-align:center;"><b>Figure 4: Network Training Performance</b></p>
<br/>
Figure 5 shows the performance of the network for several images from the dataset.<br/>
<p style="text-align:center;">
<img src="../Img/ocrres.png" height="auto" width="75%" />
</p>
<p style="text-align:center;"><b>Figure 5: Sample OCR Results</b></p>
<br/>
The text beneath each image is the predicted text produced by the network. This code was run on a laptop with integrated graphics and so the amount of data and size of the network was constrained for performance reasons. Further improvements can likely be made to the performance with a larger dataset and network.<br/><br/></div>
                <div class="BarRight" id="RBar"></div>
            </div>
        </div>
    </div>

    <div class="Footer">
        <div style="display: table; width: 100%;">
            <div style="display: table-row; height: 100%; width: 100%;">
                <div style="display: table-cell; height: 100%; width: 30%;"></div>
                <div style="display: table-cell; height: 100%; width: 20%; vertical-align: middle;">
                    <a class="LinkFooter" href="index.html">Home</a><br/><br/>
                </div>
                <div style="display: table-cell; height: 100%; width: 20%; vertical-align: middle;">
                    <text class="LinkFooter" onClick="window.scrollTo(0,0);">Top</text><br/><br/>
                </div>
                <div style="display: table-cell; height: 100%; width: 30%;"></div>
            </div>
        </div>
        <br/>
        <cite class="CiteText">2022 Nicholas T. Smith All Rights Reserved</cite>        
    </div>
</body>
</html>
